{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/tomas/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/tomas/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/tomas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/tomas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/tomas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "nltk.download(\"maxent_ne_chunker\")\n",
    "nltk.download(\"words\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def is_noise(word):\n",
    "    return (\n",
    "        word.lower() in stop_words\n",
    "        or word.isdigit()\n",
    "        or re.match(r\"^\\W+$\", word) is not None\n",
    "        or re.match(r\"[\\U0001F600-\\U0001F64F]\", word) is not None\n",
    "    )\n",
    "\n",
    "\n",
    "def is_named_entity(token):\n",
    "    tagged_token = pos_tag([token])\n",
    "    chunk = ne_chunk(tagged_token)\n",
    "    for subtree in chunk:\n",
    "        if hasattr(subtree, \"label\"):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def normalize(column):\n",
    "    return (column - column.min()) / (column.max() - column.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('babe-base-annomatic.csv').rename(columns={'Unnamed: 0':'token'})\n",
    "magpie = pd.read_csv('magpie-annomatic.csv').rename(columns={'Unnamed: 0':'token'})\n",
    "synth = pd.read_csv('roberta-anno-lexical-ft.csv').rename(columns={'Unnamed: 0':'token'})\n",
    "\n",
    "base['token'] = base['token'].astype(str)\n",
    "magpie['token'] = magpie['token'].astype(str)\n",
    "synth['token'] = synth['token'].astype(str)\n",
    "\n",
    "base = base[~base[\"token\"].apply(is_noise)]\n",
    "magpie = magpie[~magpie[\"token\"].apply(is_noise)]\n",
    "synth = synth[~synth[\"token\"].apply(is_noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE x MAGPIE: 807\n",
      "BASE x SYNTH: 792\n",
      "MAGPIE x SYNTH: 783\n"
     ]
    }
   ],
   "source": [
    "print(f\"BASE x MAGPIE: {len(np.intersect1d(base.token.tolist(),magpie.token.tolist()))}\")\n",
    "print(f\"BASE x SYNTH: {len(np.intersect1d(base.token.tolist(),synth.token.tolist()))}\")\n",
    "print(f\"MAGPIE x SYNTH: {len(np.intersect1d(magpie.token.tolist(),synth.token.tolist()))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06218049519729795"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magpie_ = magpie[magpie['attribution'] >= 0]\n",
    "magpie_[magpie_['token'].apply(is_named_entity)]['attribution'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11847788212482634"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_ = base[base['attribution'] >= 0]\n",
    "base_[base_['token'].apply(is_named_entity)]['attribution'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08675489275717088"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_ = synth[synth['attribution'] >= 0]\n",
    "synth_[synth_['token'].apply(is_named_entity)]['attribution'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = base.merge(magpie, on='token', suffixes=('_base', '_magpie')).merge(synth, on='token')\n",
    "merged_df = merged_df.rename(columns={'attribution_base':'base','attribution_magpie':'magpie','attribution':'synth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "base      0.129211\n",
       "magpie    0.049537\n",
       "synth     0.103807\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['token'].apply(is_named_entity)][['base','magpie','synth']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07500100158535464"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base['attribution'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>base</th>\n",
       "      <th>count_base</th>\n",
       "      <th>magpie</th>\n",
       "      <th>count_magpie</th>\n",
       "      <th>synth</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOP</td>\n",
       "      <td>0.121140</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040395</td>\n",
       "      <td>2</td>\n",
       "      <td>0.118335</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Obamacare</td>\n",
       "      <td>0.119445</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>3</td>\n",
       "      <td>0.066662</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Obama</td>\n",
       "      <td>0.115195</td>\n",
       "      <td>4</td>\n",
       "      <td>0.077899</td>\n",
       "      <td>2</td>\n",
       "      <td>0.169631</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Abortion</td>\n",
       "      <td>0.147291</td>\n",
       "      <td>2</td>\n",
       "      <td>0.150972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129188</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Trump</td>\n",
       "      <td>0.146611</td>\n",
       "      <td>68</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>64</td>\n",
       "      <td>0.098368</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Bannon</td>\n",
       "      <td>0.129086</td>\n",
       "      <td>2</td>\n",
       "      <td>0.075290</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Hitler</td>\n",
       "      <td>0.208815</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Wahhabism</td>\n",
       "      <td>0.148780</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>America</td>\n",
       "      <td>0.076736</td>\n",
       "      <td>8</td>\n",
       "      <td>0.070863</td>\n",
       "      <td>4</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Party</td>\n",
       "      <td>0.077661</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036822</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059879</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>China</td>\n",
       "      <td>0.108751</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>2</td>\n",
       "      <td>0.105714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Donald</td>\n",
       "      <td>0.083377</td>\n",
       "      <td>7</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>4</td>\n",
       "      <td>0.056086</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>White</td>\n",
       "      <td>0.223957</td>\n",
       "      <td>3</td>\n",
       "      <td>0.064936</td>\n",
       "      <td>2</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Hollywood</td>\n",
       "      <td>0.233686</td>\n",
       "      <td>2</td>\n",
       "      <td>0.082925</td>\n",
       "      <td>2</td>\n",
       "      <td>0.105825</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Bernie</td>\n",
       "      <td>0.122341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065348</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064945</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Rourke</td>\n",
       "      <td>-0.158198</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.100206</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.196628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Trumpism</td>\n",
       "      <td>0.171386</td>\n",
       "      <td>2</td>\n",
       "      <td>0.120402</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067478</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>American</td>\n",
       "      <td>0.110209</td>\n",
       "      <td>7</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>6</td>\n",
       "      <td>0.061884</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>-0.027738</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115626</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.257090</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.058369</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Biden</td>\n",
       "      <td>-0.021489</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>6</td>\n",
       "      <td>0.044674</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Psychosis</td>\n",
       "      <td>0.217089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116858</td>\n",
       "      <td>1</td>\n",
       "      <td>0.232266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>ISIS</td>\n",
       "      <td>0.177275</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092369</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093060</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0.154992</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022985</td>\n",
       "      <td>2</td>\n",
       "      <td>0.190312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Bill</td>\n",
       "      <td>0.257743</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078157</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080524</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.155545</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.038416</td>\n",
       "      <td>1</td>\n",
       "      <td>0.397991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Muslim</td>\n",
       "      <td>0.127017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Democracy</td>\n",
       "      <td>0.190641</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>New</td>\n",
       "      <td>0.075591</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.020784</td>\n",
       "      <td>4</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Fox</td>\n",
       "      <td>0.143339</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024841</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050036</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Christian</td>\n",
       "      <td>0.095266</td>\n",
       "      <td>3</td>\n",
       "      <td>0.031010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.096298</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>Giuliani</td>\n",
       "      <td>0.102222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052252</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>0.184174</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>Epicureanism</td>\n",
       "      <td>0.118147</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token      base  count_base    magpie  count_magpie     synth  \\\n",
       "4             GOP  0.121140           4  0.040395             2  0.118335   \n",
       "5       Obamacare  0.119445           2  0.027668             3  0.066662   \n",
       "13          Obama  0.115195           4  0.077899             2  0.169631   \n",
       "16       Abortion  0.147291           2  0.150972             1  0.129188   \n",
       "32          Trump  0.146611          68  0.060150            64  0.098368   \n",
       "43         Bannon  0.129086           2  0.075290             1  0.246865   \n",
       "60         Hitler  0.208815           1  0.125999             1  0.116705   \n",
       "65      Wahhabism  0.148780           1  0.024682             1  0.047215   \n",
       "78        America  0.076736           8  0.070863             4  0.071300   \n",
       "86          Party  0.077661           2  0.036822             2  0.059879   \n",
       "88          China  0.108751           3  0.013516             2  0.105714   \n",
       "93         Donald  0.083377           7  0.017307             4  0.056086   \n",
       "106         White  0.223957           3  0.064936             2  0.152464   \n",
       "124     Hollywood  0.233686           2  0.082925             2  0.105825   \n",
       "128        Bernie  0.122341           1  0.065348             2  0.064945   \n",
       "138        Rourke -0.158198           1 -0.100206             1 -0.196628   \n",
       "157      Trumpism  0.171386           2  0.120402             2  0.067478   \n",
       "181      American  0.110209           7  0.069208             6  0.061884   \n",
       "190       Wichita -0.027738           1  0.115626             1  0.046351   \n",
       "204    Washington  0.257090           1 -0.058369             1  0.036871   \n",
       "235         Biden -0.021489           5  0.008202             6  0.044674   \n",
       "252     Psychosis  0.217089           1  0.116858             1  0.232266   \n",
       "258          ISIS  0.177275           1  0.092369             1  0.093060   \n",
       "273     Bloomberg  0.154992           3  0.022985             2  0.190312   \n",
       "280          Bill  0.257743           1  0.078157             1  0.080524   \n",
       "281         Nancy  0.155545           2 -0.038416             1  0.397991   \n",
       "300        Muslim  0.127017           1  0.110687             1  0.330219   \n",
       "327     Democracy  0.190641           1  0.070881             1  0.169739   \n",
       "431           New  0.075591           3 -0.020784             4  0.057178   \n",
       "492           Fox  0.143339           1  0.024841             3  0.050036   \n",
       "522     Christian  0.095266           3  0.031010             3  0.096298   \n",
       "557      Giuliani  0.102222           1  0.052252             1  0.052701   \n",
       "567    Democratic  0.184174           1  0.025449             1  0.052602   \n",
       "574  Epicureanism  0.118147           1  0.028333             1  0.056700   \n",
       "\n",
       "     count  \n",
       "4        3  \n",
       "5        5  \n",
       "13       5  \n",
       "16       2  \n",
       "32      76  \n",
       "43       1  \n",
       "60       1  \n",
       "65       1  \n",
       "78       7  \n",
       "86       2  \n",
       "88       1  \n",
       "93       8  \n",
       "106      5  \n",
       "124      2  \n",
       "128      3  \n",
       "138      1  \n",
       "157      2  \n",
       "181      6  \n",
       "190      1  \n",
       "204      1  \n",
       "235      7  \n",
       "252      1  \n",
       "258      2  \n",
       "273      1  \n",
       "280      2  \n",
       "281      1  \n",
       "300      1  \n",
       "327      1  \n",
       "431      3  \n",
       "492      2  \n",
       "522      4  \n",
       "557      1  \n",
       "567      2  \n",
       "574      1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['token'].apply(is_named_entity)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
