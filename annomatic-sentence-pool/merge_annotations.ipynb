{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Load annotated data\n",
    "df_new_dataset = pd.read_csv(\"data/output/final_sentence_pool_cleaned.csv\").drop_duplicates('text', keep='first')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Master sample\n",
    "zephyr_ma = pd.read_csv(\"data/annotation/ma/zephyr-7b-beta.csv\").drop_duplicates('text', keep='first')\n",
    "openchat_ma = pd.read_csv(\"data/annotation/ma/openchat_3.5.csv\").drop_duplicates('text', keep='first')\n",
    "Llama_ma = pd.read_csv(\"data/annotation/ma/Llama-2-13b-chat-hf.csv\").drop_duplicates('text', keep='first')\n",
    "\n",
    "# rest_1\n",
    "zephyr_rest_1 = pd.read_csv(\"data/annotation/rest_1/zephyr-7b-beta.csv\").drop_duplicates('text', keep='first')\n",
    "openchat_rest_1 = pd.read_csv(\"data/annotation/rest_1/openchat_3.5.csv\").drop_duplicates('text', keep='first')\n",
    "llama_rest_1_1 = pd.read_csv(\"data/annotation/rest_1/part_1/Llama-2-13b-chat-hf.csv\").drop_duplicates('text', keep='first')\n",
    "llama_rest_1_2 = pd.read_csv(\"data/annotation/rest_1/part_2/Llama-2-13b-chat-hf.csv\").drop_duplicates('text', keep='first')\n",
    "llama_rest_1 = pd.concat([llama_rest_1_1, llama_rest_1_2], ignore_index=True)\n",
    "\n",
    "# final_part_1\n",
    "zephyr_final_part_1 = pd.read_csv(\"data/annotation/final_part_1/zephyr-7b-beta.csv\").drop_duplicates('text', keep='first')\n",
    "openchat_final_part_1= pd.read_csv(\"data/annotation/final_part_1/openchat_3.5.csv\").drop_duplicates('text', keep='first')\n",
    "llama_final_part_1_1 = pd.read_csv(\"data/annotation/final_part_1/part_1/Llama-2-13b-chat-hf.csv\").drop_duplicates('text', keep='first')\n",
    "llama_final_part_1_2 = pd.read_csv(\"data/annotation/final_part_1/part_2/Llama-2-13b-chat-hf.csv\").drop_duplicates('text', keep='first')\n",
    "llama_final_part_1 = pd.concat([llama_final_part_1_1, llama_final_part_1_2], ignore_index=True)\n",
    "\n",
    "# final_part_2\n",
    "zephyr_final_part_2 = pd.read_csv(\"data/annotation/final_part_2/zephyr-7b-beta.csv\").drop_duplicates('text', keep='first')\n",
    "openchat_final_part_2 = pd.read_csv(\"data/annotation/final_part_2/openchat_3.5.csv\").drop_duplicates('text', keep='first')\n",
    "llama_final_part_2_1 = pd.read_csv(\"data/annotation/final_part_2/part_1/Llama-2-13b-chat-hf.csv\").drop_duplicates('text', keep='first')\n",
    "llama_final_part_2_2 = pd.read_csv(\"data/annotation/final_part_2/part_2/Llama-2-13b-chat-hf.csv\").drop_duplicates('text', keep='first')\n",
    "llama_final_part_2 = pd.concat([llama_final_part_2_1, llama_final_part_2_2], ignore_index=True)\n",
    "\n",
    "# final_part_2\n",
    "zephyr_final_part_3 = pd.read_csv(\"data/annotation/final_part_3/zephyr-7b-beta.csv\").drop_duplicates('text', keep='first')\n",
    "openchat_final_part_3 = pd.read_csv(\"data/annotation/final_part_3/openchat_3.5.csv\").drop_duplicates('text', keep='first')\n",
    "llama_final_part_3 = pd.read_csv(\"data/annotation/final_part_3/Llama-2-13b-chat-hf.csv\").drop_duplicates('text', keep='first')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated Zephyr:  (65934, 5)\n",
      "Annotated Openchat:  (65934, 5)\n",
      "Annotated Llama:  (65934, 5)\n",
      "Not in Zephyr:  (0, 7)\n",
      "Not in Openchat:  (0, 7)\n",
      "Not in Llama:  (0, 7)\n"
     ]
    }
   ],
   "source": [
    "# Merge per LLM\n",
    "zephyr_all = pd.concat([zephyr_ma, zephyr_rest_1, zephyr_final_part_1, zephyr_final_part_2, zephyr_final_part_3], ignore_index=True).drop_duplicates('text', keep='first')\n",
    "openchat_all = pd.concat([openchat_ma, openchat_rest_1, openchat_final_part_1, openchat_final_part_2, openchat_final_part_3], ignore_index=True).drop_duplicates('text', keep='first')\n",
    "llama_all = pd.concat([Llama_ma, llama_rest_1, llama_final_part_1, llama_final_part_2, llama_final_part_3], ignore_index=True).drop_duplicates('text', keep='first')\n",
    "\n",
    "# drop all that NOT in master sample\n",
    "zephyr_all = pd.merge(zephyr_all, df_new_dataset[['text']], on='text', how='inner').drop_duplicates('text', keep='first')\n",
    "openchat_all = pd.merge(openchat_all, df_new_dataset[['text']], on='text', how='inner').drop_duplicates('text', keep='first')\n",
    "llama_all = pd.merge(llama_all, df_new_dataset[['text']], on='text', how='inner').drop_duplicates('text', keep='first')\n",
    "print(\"Annotated Zephyr: \", zephyr_all.shape)\n",
    "print(\"Annotated Openchat: \", openchat_all.shape)\n",
    "print(\"Annotated Llama: \", llama_all.shape)\n",
    "\n",
    "# drop all that are NOT in the master sample\n",
    "df_new_not_in_zephyr = pd.merge(df_new_dataset, zephyr_all[['text']], on='text', how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1)\n",
    "df_new_not_in_openchat = pd.merge(df_new_dataset, openchat_all[['text']], on='text', how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1)\n",
    "df_new_not_in_llama = pd.merge(df_new_dataset, llama_all[['text']], on='text', how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1)\n",
    "print(\"Not in Zephyr: \", df_new_not_in_zephyr.shape)\n",
    "print(\"Not in Openchat: \", df_new_not_in_openchat.shape)\n",
    "print(\"Not in Llama: \", df_new_not_in_llama.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "zephyr_all.to_csv(\"data/annotation/final/zephyr-7b-beta.csv\", index=False)\n",
    "openchat_all.to_csv(\"data/annotation/final/openchat_3.5.csv\", index=False)\n",
    "llama_all.to_csv(\"data/annotation/final/Llama-2-13b-chat-hf.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in media bias.\n",
      "\n",
      "Instruction: 'Watching a crazed mob tear down the statue of Christopher Columbus in Pelosi’s native Baltimore on July 4, it was impossible to believe an earlier generation of Democratic leaders would have allowed such destruction.'\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step. The sentence expresses bias as it implies a negative judgment on contemporary Democratic leaders by unfavorably comparing them to past ones, suggesting that the past leaders would not have \"allowed\" the event described. It also uses emotionally charged language like \"crazed mob\" and \"destruction,\" indicating disapproval of the actions rather than providing a neutral account. The framing presents the tearing down of the statue as universally negative, disregarding any broader context or differing viewpoints on the incident. The answer is BIASED.\n",
      "\n",
      "Instruction: 'We should expect growing support for this item for a few reasons: Younger voters of all political stripes are being exposed to the status quo student loan system. Younger voters are also less likely to accept the toxic brand of “conservatism.” '\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step. The sentence is biased because it makes value-laden statements. It implies that the current student loan system is negative by referring to it as \"status quo,\" suggesting a need for change, and it assumes that younger voters are universally dissatisfied with it. Additionally, describing \"conservatism\" as a \"toxic brand\" is a subjective judgment that conveys a negative opinion without acknowledging the diversity of conservative thought or that conservative perspectives on student loans can be legitimate. These elements show a partial perspective that favors certain political and social views. The answer is BIASED.\n",
      "\n",
      "Instruction: 'Large majorities of both parties seem to like the Green New Deal, despite efforts by Fox News to paint it as disastrous.'\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step. The sentence exhibits bias primarily through its framing and language choice. It suggests that Fox News's efforts to portray the Green New Deal negatively are at odds with the favorable opinion held by \"large majorities.\" This implicitly assigns Fox News a motive to mislead and sets up an adversarial relationship between the media outlet and public opinion. The use of \"despite\" signals that Fox News's stance should naturally influence public perception, yet it has supposedly failed to do so, indicating that the sentence writer may be attributing less credibility to Fox News's position on the matter. The answer is BIASED.\n",
      "\n",
      "Instruction: 'Brexit Party leader Nigel Farage blasted Boris Johnson for failing to confront the Marxist Black Lives Matter UK movement, saying that the prime minister is “trapped” by a politically correct culture.'\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step. The sentence contains loaded language and subjective judgments. Terms like \"blasted\" and \"confront\" suggest confrontation and conflict. \"Marxist Black Lives Matter UK movement\" is a politically charged description implying negative connotations, likely alienating to supporters of the movement. \"Trapped by a politically correct culture\" implies weakness and suggests a negative view of sensitivity to inclusivity. These elements collectively reveal a one-sided perspective lacking neutral reporting, thereby classifying the sentence as biased. The answer is BIASED.\n",
      "\n",
      "Instruction: 'On the first point, Vox had a good piece yesterday noting that ISIS territory is only one piece of a larger puzzle.'\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step. The sentence suggests that the information from Vox is particularly noteworthy or valuable (\"had a good piece\"), which implies a positive evaluation of the source. By qualifying Vox's article as 'good', it indicates a subjective judgment that reflects the writer’s opinion or preference toward Vox's coverage. This use of evaluative language introduces bias by endorsing the credibility or quality of Vox over other sources without providing evidence or rationale for this judgment. Bias can arise from the use of adjectives that convey approval or disapproval, leading readers to trust one source over others. The answer is BIASED.\n",
      "\n",
      "Instruction: 'Today’s mainstream media doesn’t want you to remember, but the early days of feminism were rife with ideological battles and  backstabbing that would put a medieval court to shame.'\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step. The sentence portrays mainstream media as having an active agenda against public memory and characterizes the early days of feminism in a hyperbolic and negative light, suggesting excessive conflict with words like \"rife,\" \"ideological battles,\" and \"backstabbing.\" Such language is emotionally charged and presents a one-sided, judgemental perspective, indicative of bias rather than objective reporting. The comparison to a \"medieval court\" further dramatizes the statement, distancing it from a neutral, fact-based account. The answer is BIASED.\n",
      "\n",
      "Instruction: 'The 2010s saw the U.S. economy achieve its longest-ever expansion, with notable milestones such as 110 months of uninterrupted job gains and an unemployment rate near a half-century low becoming easy bragging points for politicians and economists alike.'\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step. The sentence is labeled as biased because it selectively highlights positive economic outcomes from the 2010s, such as the record expansion and low unemployment, implying a favorable interpretation. It employs terms like \"notable milestones\" and \"easy bragging points,\" which suggest pride and achievement without acknowledging any negative aspects or challenges that occurred during the same period. The phrasing could be seen as favoring a particular political or economic narrative that emphasizes success without a balanced view of the era’s complexities. The answer is BIASED.\n",
      "\n",
      "Instruction: 'Naturally, of course, right-wingers reacted in the ugliest way possible: By arguing that Thunberg’s identity — as a young person, as a person on the autism spectrum and, although they are careful not to say this directly, as a girl — inherently discredits what she has to say.'\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step. The sentence is biased because it makes a generalized negative assumption about \"right-wingers,\" suggesting they uniformly react in the \"ugliest way possible,\" discrediting Greta Thunberg based on her age, autism, and gender. This broad characterization does not account for varied perspectives within a political group and presupposes a malicious intent without specific evidence. It uses emotionally charged language (\"ugliest way\") that portrays one side as inherently wrong or villainous, rather than presenting a neutral or balanced viewpoint. Bias is evident in the tone and the sweeping generalization about a group's reaction to Thunberg’s activism. The answer is BIASED.\n",
      "\n",
      "Instruction: 'A few years ago, the far-right Britain First claimed that 5,000 of its members had joined the Tory party.'\n",
      "\n",
      "Classify the sentence above as BIASED or NOT BIASED.\n",
      "\n",
      "Output: Let's think step by step.\n"
     ]
    }
   ],
   "source": [
    "print(openchat_all.loc[1, 'query'])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
