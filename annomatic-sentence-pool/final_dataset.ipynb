{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/output/final_sentence_pool_annotated.parquet\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "0    39429\n1    26480\nName: final_label, dtype: int64"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"final_label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "label_zephyr  label_openchat  label_llama  final_label\n0             0               0            0              0.440547\n1             1               1            1              0.269341\n0             1               0            0              0.103840\n1             1               0            1              0.065424\n0             1               1            1              0.058019\n              0               1            0              0.036717\n1             0               0            0              0.017130\n                              1            1              0.008982\ndtype: float64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"label_zephyr\",\"label_openchat\",\"label_llama\",\"final_label\"]].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "source_party  final_label\nLean Left     0              0.152195\nCenter        0              0.133988\nLeft          0              0.131970\nRight         1              0.124080\n              0              0.096057\nLeft          1              0.094297\nLean Right    0              0.084025\nLean Left     1              0.074406\nLean Right    1              0.068883\nCenter        1              0.040101\ndtype: float64"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"source_party\",\"final_label\"]].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove sentence (conservative)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text source_party  \\\n0      Advertisement Initially, the conference attrac...        Right   \n1      The number of workers maintaining wind turbine...         Left   \n2      How did a virus like this get from a bat to a ...         Left   \n3      Sin was conceived in a garden, takes root in e...   Lean Right   \n4      The two countries have warred over this territ...   Lean Right   \n...                                                  ...          ...   \n65904  The Gig Economy is Coming. What Will It Mean F...         Left   \n65905  He arrived, freshly graduated, and told me he ...       Center   \n65906  This is not a good time for American higher ed...        Right   \n65907  Halls pleaded no contest in March to a misdeme...       Center   \n65908  Orcutt also took his electric guitar quartet o...    Lean Left   \n\n                     source_name  bias_estimate  model_uncertainity  \\\n0                       townhall              0                   0   \n1                       alternet              0                   0   \n2                       alternet              1                   0   \n3             the-christian-post              1                   0   \n4             the-christian-post              0                   0   \n...                          ...            ...                 ...   \n65904                   alternet              0                   0   \n65905  christian-science-monitor              0                   0   \n65906           american-thinker              1                   0   \n65907                       cnbc              0                   0   \n65908                        npr              1                   0   \n\n                                sentence_id  \\\n0      bd51e6ee-8e88-4901-875d-8c5151b42692   \n1      681738a3-6f56-4124-aae4-52bf803c4d22   \n2      1050d536-e626-4647-9cc5-12b731d99077   \n3      d3910f76-fca5-44cf-98ff-c89b744743e2   \n4      c9c2c432-d67c-450b-b6d3-1fbd3e4951df   \n...                                     ...   \n65904  57e37079-3ab5-4a80-95a7-867256f089e7   \n65905  4593350c-36d1-44ed-b6b0-4fb8655b55b7   \n65906  92adcba8-bd22-4c3e-8bd5-af58c45ce9fa   \n65907  81f1f6cf-b8e6-436d-ad2b-3d56c4e9c110   \n65908  cae57a11-b669-40d0-8305-f6ad7d23cb41   \n\n                                 article_id  label_zephyr  \\\n0      f87a85cb-a8d7-4a63-b71d-50342f2022c3             0   \n1      62e545ca-11ee-44be-9422-54eff5b1680e             0   \n2      f54d2a6e-a1dd-42a5-af86-866e5fe8680e             0   \n3      12f3585f-d850-4d33-8b1c-d4e25cc4896b             1   \n4      715e6c9e-1b12-4341-9f26-3c00c246ee1b             0   \n...                                     ...           ...   \n65904  8c907329-affd-4446-9ea4-0bdae1ed04cd             0   \n65905  fb4c99c1-488b-4337-be4d-c2208a249602             0   \n65906  e517de10-85b8-4273-b392-3495a70f4af5             0   \n65907  8e89132c-acc2-4b5e-a6e4-b51a9f2d4d2e             0   \n65908  c5ba0671-15db-4cff-94e0-d5df7619ccba             0   \n\n                                         response_zephyr  label_openchat  \\\n0      The sentence is not biased because it presents...               0   \n1      The sentence presents a factual statement abou...               0   \n2      The sentence is classified as not biased becau...               0   \n3      The sentence is biased because it presents a r...               1   \n4      The sentence is not biased because it presents...               0   \n...                                                  ...             ...   \n65904  The sentence is neutral because it presents a ...               0   \n65905  The sentence is not biased because it presents...               0   \n65906  The sentence is classified as not biased becau...               1   \n65907  The sentence presents a factual account of an ...               0   \n65908  The sentence is not biased because it presents...               1   \n\n                                       response_openchat  label_llama  \\\n0      The sentence is not biased because it presents...            0   \n1      The sentence provides factual information from...            0   \n2      The sentence is classified as not biased becau...            0   \n3      The sentence is biased because it presents a r...            1   \n4      The sentence is not biased because it presents...            0   \n...                                                  ...          ...   \n65904  The sentence is a neutral statement that intro...            0   \n65905  The sentence is not biased because it presents...            0   \n65906  The sentence is biased because it uses loaded ...            1   \n65907  The sentence is factual and neutral, providing...            0   \n65908  The sentence is biased because it uses subject...            0   \n\n                                          response_llama  final_label  \n0      The sentence is not biased because it presents...            0  \n1      The sentence presents a factual statement abou...            0  \n2      The sentence is not biased because it is a fac...            0  \n3      The sentence is biased because it presents a r...            1  \n4      The sentence is not biased because it presents...            0  \n...                                                  ...          ...  \n65904  The sentence presents a question that invites ...            0  \n65905  The sentence is neutral and not biased because...            0  \n65906  The sentence is biased because it uses negativ...            1  \n65907  The sentence reports on a legal matter without...            0  \n65908  The sentence is neutral because it uses object...            0  \n\n[64712 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>source_party</th>\n      <th>source_name</th>\n      <th>bias_estimate</th>\n      <th>model_uncertainity</th>\n      <th>sentence_id</th>\n      <th>article_id</th>\n      <th>label_zephyr</th>\n      <th>response_zephyr</th>\n      <th>label_openchat</th>\n      <th>response_openchat</th>\n      <th>label_llama</th>\n      <th>response_llama</th>\n      <th>final_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Advertisement Initially, the conference attrac...</td>\n      <td>Right</td>\n      <td>townhall</td>\n      <td>0</td>\n      <td>0</td>\n      <td>bd51e6ee-8e88-4901-875d-8c5151b42692</td>\n      <td>f87a85cb-a8d7-4a63-b71d-50342f2022c3</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The number of workers maintaining wind turbine...</td>\n      <td>Left</td>\n      <td>alternet</td>\n      <td>0</td>\n      <td>0</td>\n      <td>681738a3-6f56-4124-aae4-52bf803c4d22</td>\n      <td>62e545ca-11ee-44be-9422-54eff5b1680e</td>\n      <td>0</td>\n      <td>The sentence presents a factual statement abou...</td>\n      <td>0</td>\n      <td>The sentence provides factual information from...</td>\n      <td>0</td>\n      <td>The sentence presents a factual statement abou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How did a virus like this get from a bat to a ...</td>\n      <td>Left</td>\n      <td>alternet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1050d536-e626-4647-9cc5-12b731d99077</td>\n      <td>f54d2a6e-a1dd-42a5-af86-866e5fe8680e</td>\n      <td>0</td>\n      <td>The sentence is classified as not biased becau...</td>\n      <td>0</td>\n      <td>The sentence is classified as not biased becau...</td>\n      <td>0</td>\n      <td>The sentence is not biased because it is a fac...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sin was conceived in a garden, takes root in e...</td>\n      <td>Lean Right</td>\n      <td>the-christian-post</td>\n      <td>1</td>\n      <td>0</td>\n      <td>d3910f76-fca5-44cf-98ff-c89b744743e2</td>\n      <td>12f3585f-d850-4d33-8b1c-d4e25cc4896b</td>\n      <td>1</td>\n      <td>The sentence is biased because it presents a r...</td>\n      <td>1</td>\n      <td>The sentence is biased because it presents a r...</td>\n      <td>1</td>\n      <td>The sentence is biased because it presents a r...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The two countries have warred over this territ...</td>\n      <td>Lean Right</td>\n      <td>the-christian-post</td>\n      <td>0</td>\n      <td>0</td>\n      <td>c9c2c432-d67c-450b-b6d3-1fbd3e4951df</td>\n      <td>715e6c9e-1b12-4341-9f26-3c00c246ee1b</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65904</th>\n      <td>The Gig Economy is Coming. What Will It Mean F...</td>\n      <td>Left</td>\n      <td>alternet</td>\n      <td>0</td>\n      <td>0</td>\n      <td>57e37079-3ab5-4a80-95a7-867256f089e7</td>\n      <td>8c907329-affd-4446-9ea4-0bdae1ed04cd</td>\n      <td>0</td>\n      <td>The sentence is neutral because it presents a ...</td>\n      <td>0</td>\n      <td>The sentence is a neutral statement that intro...</td>\n      <td>0</td>\n      <td>The sentence presents a question that invites ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>65905</th>\n      <td>He arrived, freshly graduated, and told me he ...</td>\n      <td>Center</td>\n      <td>christian-science-monitor</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4593350c-36d1-44ed-b6b0-4fb8655b55b7</td>\n      <td>fb4c99c1-488b-4337-be4d-c2208a249602</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>0</td>\n      <td>The sentence is neutral and not biased because...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>65906</th>\n      <td>This is not a good time for American higher ed...</td>\n      <td>Right</td>\n      <td>american-thinker</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92adcba8-bd22-4c3e-8bd5-af58c45ce9fa</td>\n      <td>e517de10-85b8-4273-b392-3495a70f4af5</td>\n      <td>0</td>\n      <td>The sentence is classified as not biased becau...</td>\n      <td>1</td>\n      <td>The sentence is biased because it uses loaded ...</td>\n      <td>1</td>\n      <td>The sentence is biased because it uses negativ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65907</th>\n      <td>Halls pleaded no contest in March to a misdeme...</td>\n      <td>Center</td>\n      <td>cnbc</td>\n      <td>0</td>\n      <td>0</td>\n      <td>81f1f6cf-b8e6-436d-ad2b-3d56c4e9c110</td>\n      <td>8e89132c-acc2-4b5e-a6e4-b51a9f2d4d2e</td>\n      <td>0</td>\n      <td>The sentence presents a factual account of an ...</td>\n      <td>0</td>\n      <td>The sentence is factual and neutral, providing...</td>\n      <td>0</td>\n      <td>The sentence reports on a legal matter without...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>65908</th>\n      <td>Orcutt also took his electric guitar quartet o...</td>\n      <td>Lean Left</td>\n      <td>npr</td>\n      <td>1</td>\n      <td>0</td>\n      <td>cae57a11-b669-40d0-8305-f6ad7d23cb41</td>\n      <td>c5ba0671-15db-4cff-94e0-d5df7619ccba</td>\n      <td>0</td>\n      <td>The sentence is not biased because it presents...</td>\n      <td>1</td>\n      <td>The sentence is biased because it uses subject...</td>\n      <td>0</td>\n      <td>The sentence is neutral because it uses object...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>64712 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# strange starts\n",
    "df = df[~df['text'].str.islower()]\n",
    "df = df[~df['text'].str.startswith(\"(\")]\n",
    "df = df[~df['text'].str.startswith(\"*\")]\n",
    "df = df[~df['text'].str.startswith(\"-\")]\n",
    "df = df[~df['text'].str.startswith(\"ðŸ”¥\")]\n",
    "df = df[~df['text'].str.startswith(\"$\")]\n",
    "df = df[~df['text'].str.startswith(\"âž¼\")]\n",
    "df = df[~df['text'].str.startswith(\"ðŸ“¹\")]\n",
    "df = df[~df['text'].str.startswith(\"â™ª\")]\n",
    "df = df[~df['text'].str.startswith(\"â™ª\")]\n",
    "df = df[~df['text'].str.startswith(\"â€ \")]\n",
    "df = df[~df['text'].str.startswith(\"â™¬\")]\n",
    "df = df[~df['text'].str.startswith(\">\")]\n",
    "df = df[~df['text'].str.startswith(\":\")]\n",
    "pattern = re.compile(r\"\\d+% \\(\\d+ Votes\\) \\d+% \\(\\d+ Votes\\)\")\n",
    "# Use str.contains with the regex pattern to filter rows\n",
    "df = df[~df['text'].str.contains(pattern)]\n",
    "df = df[~df['text'].str.startswith(\".\")]\n",
    "df = df[~df['text'].str.startswith(\"!\")]\n",
    "df = df[~df['text'].str.startswith('\"')]\n",
    "\n",
    "# TODO exclude stuff starting with 'YOU' variations <- opinionated\n",
    "df = df[~df['text'].str.startswith(\"You \")]\n",
    "df = df[~df['text'].str.startswith(\"Youâ€™ve \")]\n",
    "df = df[~df['text'].str.startswith(\"Youâ€™ll \")]\n",
    "df = df[~df['text'].str.startswith(\"Youâ€™re \")]\n",
    "df = df[~df['text'].str.startswith(\"Youâ€™d \")]\n",
    "\n",
    "# TODO exclude stuff starting with 'I' variations <- opinionated\n",
    "df = df[~df['text'].str.startswith(\"I've \")]\n",
    "df = df[~df['text'].str.startswith(\"Iâ€™ve \")]\n",
    "df = df[~df['text'].str.startswith(\"Iâ€™m \")]\n",
    "df = df[~df['text'].str.startswith(\"I'm \")]\n",
    "df = df[~df['text'].str.startswith(\"I'd \")]\n",
    "df = df[~df['text'].str.startswith(\"I'll \")]\n",
    "df = df[~df['text'].str.startswith(\"I,\")]\n",
    "\n",
    "indices_to_check = [6557, 58590, 17440, 43192, 10127, 27994, 35381]\n",
    "rows_to_drop = df[df.index.isin(indices_to_check)]\n",
    "df.drop(rows_to_drop.index, inplace=True)\n",
    "\n",
    "df.to_parquet(\"data/output/final_sentence_pool_annotated_conservative.parquet\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0    38704\n1    26008\nName: final_label, dtype: int64"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.final_label.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "label_zephyr  label_openchat  label_llama  final_label\n0             0               0            0              0.440537\n1             1               1            1              0.269795\n0             1               0            0              0.103659\n1             1               0            1              0.065645\n0             1               1            1              0.057439\n              0               1            0              0.036577\n1             0               0            0              0.017323\n                              1            1              0.009025\ndtype: float64"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"label_zephyr\",\"label_openchat\",\"label_llama\",\"final_label\"]].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "source_party\nLean Left       14680\nLeft            14657\nRight           14263\nCenter          11207\nLean Right       9905\ndtype: int64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"source_party\"]].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create final sample out of this\n",
    "\n",
    "- we want ~ equal labels\n",
    "- we want ~ equal parties"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text source_party  \\\n",
      "55199  This conflict redefined the regional landscape...        Right   \n",
      "25137  The requirement to sign and date a ballot enve...        Right   \n",
      "35988  In May, the roving dining series known as Lev,...         Left   \n",
      "6163   To write his biography requires a command of n...         Left   \n",
      "60403  From Cooper, whose prosthetic makeup in the ea...       Center   \n",
      "\n",
      "                     source_name  bias_estimate  model_uncertainity  \\\n",
      "55199                    newsmax              0                   0   \n",
      "25137           american-thinker              1                   0   \n",
      "35988          new-york-magazine              1                   1   \n",
      "6163                the-atlantic              0                   0   \n",
      "60403  christian-science-monitor              1                   0   \n",
      "\n",
      "                                sentence_id  \\\n",
      "55199  f23fb786-6f15-4967-87d4-ccbb95cef09b   \n",
      "25137  ecc070d9-896e-4ed9-b76e-3b6ee6936791   \n",
      "35988  f34b23b9-f6c3-492b-8de2-390715e9aef2   \n",
      "6163   828722d1-1f52-47fe-b432-c8fdb180f268   \n",
      "60403  c8aab78f-69a9-4a55-b686-52a0bef2e4f5   \n",
      "\n",
      "                                 article_id  label_zephyr  \\\n",
      "55199  24317a4c-43a6-4b8a-9399-b2ade6453975             0   \n",
      "25137  d4466d1d-9486-4293-97e8-76c3cd55027d             1   \n",
      "35988  b737c72c-a13b-4261-a29e-11774026f45b             0   \n",
      "6163   1b39b762-807c-43f8-bf12-1f94314131ae             0   \n",
      "60403  62cbd129-dc28-4706-85aa-5aae7140ef91             1   \n",
      "\n",
      "                                         response_zephyr  label_openchat  \\\n",
      "55199  The sentence is labeled as not biased because ...               1   \n",
      "25137  The sentence exhibits bias by implying that le...               1   \n",
      "35988  The sentence is not biased because it presents...               1   \n",
      "6163   The sentence is labeled as not biased because ...               0   \n",
      "60403  The sentence is biased because it uses subject...               1   \n",
      "\n",
      "                                       response_openchat  label_llama  \\\n",
      "55199  The sentence is labeled as biased because it p...            0   \n",
      "25137  The sentence is biased because it uses the ter...            1   \n",
      "35988  The sentence is biased because it uses the ter...            1   \n",
      "6163   The sentence is not biased because it is a str...            0   \n",
      "60403  The sentence is biased because it uses negativ...            1   \n",
      "\n",
      "                                          response_llama  final_label  \n",
      "55199  The sentence is neutral in its description of ...            0  \n",
      "25137  The sentence is biased because it implies that...            1  \n",
      "35988  The sentence is biased because it uses positiv...            1  \n",
      "6163   The sentence is not biased as it simply states...            0  \n",
      "60403  The sentence is biased because it uses negativ...            1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "desired_sample_size_per_label = min(df[\"final_label\"].value_counts())\n",
    "\n",
    "# Get unique sources\n",
    "all_sources = df['source_party'].unique()\n",
    "\n",
    "# Create empty DataFrames for the final samples\n",
    "final_sample_label_0 = pd.DataFrame()\n",
    "final_sample_label_1 = pd.DataFrame()\n",
    "\n",
    "# Sample uniformly for each label and each source\n",
    "for source in all_sources:\n",
    "    source_subset_label_0 = df[(df['final_label'] == 0) & (df['source_party'] == source)]\n",
    "    source_subset_label_1 = df[(df['final_label'] == 1) & (df['source_party'] == source)]\n",
    "\n",
    "    sample_size_label_0 = min(desired_sample_size_per_label, len(source_subset_label_0))\n",
    "    sample_size_label_1 = min(desired_sample_size_per_label, len(source_subset_label_1))\n",
    "\n",
    "    source_subset_sampled_label_0 = source_subset_label_0.sample(n=sample_size_label_0, random_state=42)\n",
    "    source_subset_sampled_label_1 = source_subset_label_1.sample(n=sample_size_label_1, random_state=42)\n",
    "\n",
    "    final_sample_label_0 = pd.concat([final_sample_label_0, source_subset_sampled_label_0])\n",
    "    final_sample_label_1 = pd.concat([final_sample_label_1, source_subset_sampled_label_1])\n",
    "\n",
    "# Ensure both labels have the desired sample size\n",
    "final_sample_label_0 = final_sample_label_0.head(desired_sample_size_per_label)\n",
    "final_sample_label_1 = final_sample_label_1.head(desired_sample_size_per_label)\n",
    "\n",
    "# Combine both label samples\n",
    "final_sample_balanced = pd.concat([final_sample_label_0, final_sample_label_1])\n",
    "\n",
    "# Shuffle the final sample\n",
    "final_sample_balanced = final_sample_balanced.sample(frac=1, random_state=42)\n",
    "\n",
    "# Check the first few rows of the final sample\n",
    "print(final_sample_balanced.head())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "Left          14657\nRight         14263\nLean Left     10605\nLean Right     9905\nCenter         2586\nName: source_party, dtype: int64"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sample_balanced.source_party.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "0    26008\n1    26008\nName: final_label, dtype: int64"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sample_balanced.final_label.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "final_sample_balanced.to_parquet(\"data/output/final_sentence_pool_annotated_conservative_balanced.parquet\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
