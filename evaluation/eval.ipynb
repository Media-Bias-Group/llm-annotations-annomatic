{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import matthews_corrcoef,precision_score,recall_score,f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_babe_test=pd.read_csv('babe_test_annomatic.csv')\n",
    "\n",
    "df_babe_test=df_babe_test[['text','label','zephyr_label','openchat_label','llama_13b_label','majority','magpie','synth','babe']]\n",
    "df_babe_test=df_babe_test[df_babe_test['zephyr_label']!=\"?\"]\n",
    "\n",
    "df_babe_test['zephyr_label'] = df_babe_test['zephyr_label'].astype(int)\n",
    "df_babe_test['openchat_label'] = df_babe_test['openchat_label'].astype(int)\n",
    "df_babe_test['llama_13b_label'] = df_babe_test['llama_13b_label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basil = pd.read_csv('basil_synth_babe_preds.csv')\n",
    "df_basil=df_basil[~df_basil.synth_pred.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(data,source:str,target:str):\n",
    "    precision = precision_score(y_true=data[source],y_pred=data[target],average='binary')\n",
    "    recall = recall_score(y_true=data[source],y_pred=data[target],average='binary')\n",
    "    print(f\"P: {precision}\")\n",
    "    print(f\"R: {recall}\")\n",
    "    print(f\"F1: {2 * ((precision * recall) / (precision + recall))}\")\n",
    "    print(f\"MCC: {matthews_corrcoef(y_true=data[source],y_pred=data[target])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval BABE test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.8307692307692308\n",
      "R: 0.7728085867620751\n",
      "F1: 0.8007414272474515\n",
      "MCC: 0.5697130131956829\n"
     ]
    }
   ],
   "source": [
    "# Annotator #1\n",
    "get_scores(data=df_babe_test,source='label',target='zephyr_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.8144876325088339\n",
      "R: 0.8246869409660107\n",
      "F1: 0.8195555555555555\n",
      "MCC: 0.587635513179489\n"
     ]
    }
   ],
   "source": [
    "# Annotator #2\n",
    "get_scores(data=df_babe_test,source='label',target='openchat_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.827708703374778\n",
      "R: 0.8336314847942755\n",
      "F1: 0.8306595365418895\n",
      "MCC: 0.614285145672567\n"
     ]
    }
   ],
   "source": [
    "# Annotator #3\n",
    "get_scores(data=df_babe_test,source='label',target='llama_13b_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.8518518518518519\n",
      "R: 0.8228980322003577\n",
      "F1: 0.8371246587807097\n",
      "MCC: 0.6390586829640236\n"
     ]
    }
   ],
   "source": [
    "# majority\n",
    "get_scores(data=df_babe_test,source='label',target='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.8973305954825462\n",
      "R: 0.7817531305903399\n",
      "F1: 0.8355640535372849\n",
      "MCC: 0.6639293573226216\n"
     ]
    }
   ],
   "source": [
    "# magpie\n",
    "get_scores(data=df_babe_test,source='label',target='magpie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.875\n",
      "R: 0.813953488372093\n",
      "F1: 0.8433734939759036\n",
      "MCC: 0.6624344914259455\n"
     ]
    }
   ],
   "source": [
    "# synth\n",
    "get_scores(data=df_babe_test,source='label',target='synth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.9152542372881356\n",
      "R: 0.7728085867620751\n",
      "F1: 0.8380213385063046\n",
      "MCC: 0.6784047466439473\n"
     ]
    }
   ],
   "source": [
    "# babe\n",
    "get_scores(data=df_babe_test,source='label',target='babe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval BASIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.15841584158415842\n",
      "R: 0.3747072599531616\n",
      "F1: 0.22268615170494085\n",
      "MCC: 0.1637080886035334\n"
     ]
    }
   ],
   "source": [
    "# babe\n",
    "get_scores(data=df_basil,source='lex_label',target='babe_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.15993907083015993\n",
      "R: 0.4918032786885246\n",
      "F1: 0.2413793103448276\n",
      "MCC: 0.1948816352518775\n"
     ]
    }
   ],
   "source": [
    "# synth\n",
    "get_scores(data=df_basil,source='lex_label',target='synth_pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# synth preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(data:pd.DataFrame,checkpoint:str):\n",
    "        \"\"\"\n",
    "        Generates predictions for the test data using the trained model.\n",
    "\n",
    "        Returns:\n",
    "            predictions (list): List of predicted labels for the test data.\n",
    "        \"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "        device = (\n",
    "            torch.device(\"cuda:0\")\n",
    "            if torch.cuda.is_available()\n",
    "            else torch.device(\"cpu\")\n",
    "        )\n",
    "        model.to(device)\n",
    "        tok = tokenizer(\n",
    "            list(data[\"text\"]),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        testing_dataloader = DataLoader(\n",
    "            Dataset.from_dict(tok), batch_size=8, collate_fn=data_collator\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        for batch in tqdm(testing_dataloader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=-1).tolist())\n",
    "\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:20<00:00,  5.09s/it]\n"
     ]
    }
   ],
   "source": [
    "df_babe_test['synth'] = make_predictions(data=df_babe_test,checkpoint='anonymous/roberta-anno-lexical-ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [06:03<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "df_babe_test['magpie'] = make_predictions(data=df_babe_test,checkpoint='anonymous/magpie-annomatic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [04:54<00:00,  2.35s/it]\n"
     ]
    }
   ],
   "source": [
    "df_babe_test['babe'] = make_predictions(data=df_babe_test,checkpoint='anonymous/babe-base-annomatic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
